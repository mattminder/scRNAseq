\documentclass[10pt,conference,compsocconf]{IEEEtran}

\usepackage{hyperref}
\usepackage{graphicx}	% For figure environment
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{float}
\usepackage{url}
\newcommand{\beginsupplement}{%
	\setcounter{table}{0}
	\renewcommand{\thetable}{S\arabic{table}}%
	\setcounter{figure}{0}
	\renewcommand{\thefigure}{S\arabic{figure}}%
}

\begin{document}
\title{CS-433 Machine Learning Project 2}

\author{
  Matthias Minder, Zora Oswald, Silvan Stettler\\
}

\maketitle

\begin{abstract}
Abstract...
\end{abstract}

\section*{Introduction} 
The recently developed method of single cell RNA sequencing (scRNA-seq) allows to measure the amount of RNA from a specific gene on a single cell resolution. This gives valuable insights into the properties and cellular function of single cells in a whole population of cells. High throughput methods allow to analyze thousands of cells simultaneously. scRNA-seq results in so-called read-count matrices (RCMs) which indicate for a given gene how many times it was expressed in a given cell.
\par 
The emergence of scRNA-seq has lead to the discovery of many new cell types based on their gene expression profile. The question thus naturally arises whether it would be possible to predict cell types using a machine learning approach. Of special interest is the detection and \textit{de novo} discovery of stem cells in tissues for which no stem cell population has been characterized. This project aims to create a classifier able to assign a "stemness" score to cells based on scRNA-seq data. 
\par
However, several challenges are associated with working with scRNA-seq data. The three most predominant issues are the following: Differences in procedures give rise to batch effects, leading to substantial overall differences between datasets of different sources. Secondly, cell-type annotation is based on clusters of the dataset itself, which may lead to biases when basing analysis on the annotated clusters. Thirdly, the obtained data is perturbed by drop-outs, where the read-counts for a given gene is measured to be zero, even if there were a signal. The result is that read count matrices are very sparse. 
\par
Additional issues arises from a machine learning perspective: Since the expression of different genes can be functionally related or controlled by the same transcriptional regulatory program, some features are highly correlated. However, due to the noisy nature of the data, identifying highly correlated features is hard. The scRNA-seq data can thus be thought of to be on a sub-dimensional manifold. Accurate representation of this manifold is key for obtaining stable results that generalize well to other data sets, overcoming batch-effects. Moreover, a good such representation also reduces the impact of drop-outs, since correlated genes should correct the drop-out of one-another. This nature of scRNA-data suggests that application of dimensionality reduction prior to method training will yield results that perform better on independent test data. 
\par
Within this report, we compare the prediction performance of different stem cell classifiers based on on an independent test set in order to finally determine a best-performing classifier. The presented classifiers are different, well-established machine learning methods which were trained on data transformed with different data transformations and dimensionality reduction techniques. 

\section*{Methods}
\subsection{Experimental Setup}
For the entire analysis, 17 publicly available datasets were used [CITATION]. These data sets were split into three sets, train set (eleven data sets), test set (three data sets) and the generalization train set (four data sets). Two types of classifiers were trained, which will be called basic and nested classifiers. The basic classifiers were trained on the training set, and their predictive performance was assessed in terms of accuracy on the test set. The nested classifiers were trained as follows: Using the basic classifiers, predictions were generated for the data in the generalization train set. Then, the resulting predictions by all basic classifiers were used as training set for a second classifier, whose performance was assessed on the test set. By constructing the two-layer nested classifiers, we hoped to be able to obtain a final model which is less prone to batch effects. 
Different basic classifiers were trained on a total of eight data transformations described below, of which six are network-based. 

\subsection{Dataset Preparation}
Cell type annotation was based on the clustering done in the original papers. All three sets consist only of cells which were determined as being stem or non-stem in order to avoid introducing a bias into the model. Notably, progenitors, endothelial and fibroblast cells were excluded from the analysis. For the train set, the cells were down-sampled to be of equal proportions from the three different germ layers, and within each germ layer 50\% stem and 50\% non-stem. This was chosen in order to avoid introducing a tissue-specific bias in determining stem-ness. 
\par
Since different datasets measure the expression of different genes, one has to choose which genes to use for the analysis in order to be able to fuse different datasets. The genes retained for our analysis were selected as follows: For all eleven sets within our train set, we determined whether they contained stem cells, non-stem cells or both. Then, the genes represented in all sets with stem-cells was combined with the genes represented in all sets containing non-stem cells. The reasoning behind this was that in this way, genes that are only expressed in one category of cells, stem or non-stem, are retained while minimizing the number of genes with missing values. This resulted in 13'587 genes retained for further analysis.
\par
For datasets in which a necessary gene isn't represented, we set the gene expression to zero. This is based on the heuristic that such genes are lowly expressed in these datasets, as otherwise they would have been sufficiently measured to be retained in the final dataset. 
\par
After retaining only the necessary genes and filling missing values with zero, we normalized the expression values to transcripts per million before transforming the values with $ln(1+x)$. This is standard procedure for scRNA-seq data. All subsequent transformations and training steps was based on data in this format. 

\subsection{Dimensionality Reductions}
The dimensionality of the data was reduced using conventional Principal Component Analysis (PCA) and two methods based on graph signal processing (GSP) on a graph constructed using a protein interaction network.
\par
Taking into account external information about the underlying structure is another way to reduce the influence of set specific batch effects. To this effect, we included a protein interaction network, which we then use as topology to process the expression signal. Protein interaction networks are representations of the physical and biochemical interaction between proteins in an organism. By linking proteins with the genes encoding them, a protein interaction network can be converted to a gene network. 
\par
In the protein interaction network used here, the weight of the edges between individual proteins, which form the nodes, are a measure of how confidently an interaction can be judged to be true. The protein interaction data that was used is available in the STRING database (\url{www.string-db.org}) \cite{Szklarczyk2016}. By replacing each protein in the network with the gene that encodes it, a gene network can be created. The genome along with the corresponding expressed proteins for \textit{mus musculus} are available in the Ensembl database (\url{www.ensembl.org}) \cite{Zerbino2017}. For the creation of our network, only the proteins that could be associated to an expressing gene were kept.
Self-loops that resulted from genes whose expression produces multiple proteins and isolated nodes (no link to another node) were removed, yielding a network with 20330 genes forming nodes that are connected by 11'856'336 edges. It has to be mentioned that the gene network is constructed based on the entire dataset that was available from the sources mentioned above. Contrary to the analysed data, the scope of the network does not limit itself to the genes found in a particular type of cells, such as tissue.  \\
The process of creating the gene network is schematically shown in \ref{fig:network_creation}.
\begin{figure}
	\centering
	\includegraphics[width=0.45\textwidth]{network.png}
	\label{fig:network_creation}
	\caption{Schematic of network creation}
\end{figure}
In TODO the genes \textit{A, B, C, D} in blue are associated with the proteins that their expression produces. It is possible that the expression of a gene can result in multiple proteins, such as the gene \textbf{C} that codes for proteins \textit{c} and \textit{d}. The nodes in the original protein interaction network are then replaced with the gene that is responsible for their creation. In the case of the genes \textit{A} and \textit{C} in Figure \ref{fig:network_creation}, this yields two edges between the same genes. Thus, such genes are linked with only one edge with a weight equal to the sum of all the incident edge weights to the concerned proteins. The self-loops that might occur due to two linked proteins being expressed by the same gene such as \textit{c} and \textit{d} in the above example are removed. Proteins that could not be associated to a gene or vice versa are also removed from the network.
The original score $s_{ij}$ of a link between nodes $i$ and $j$ was used to compute an equivalent distance, where high scores result in a short distance. Subsequently, new link weights $W_{ij}$ were set using a Gaussian kernel.

\begin{align}
d_{ij} &= \frac{1}{s_{ij}} \\
W_{ij} &= exp (- \frac{d_{ij}^2}{2 \sigma^2})
\end{align}
\par

The scRNA-sec data can be transformed into a graph signal by assigning the count of expressed genes to the corresponding gene in the network, yielding a signal $\boldsymbol{x} \in \mathbb{R}^N$, where $N$ is the total number of nodes. Genes whose expression was not present as a feature in the scRNA-sec data are assigned 0. \\
After mapping the data onto the resulting graph, graph signal processing (GSP) can be leveraged to find a lower-dimensional manifold that embeds the original data, based purely on the interaction of the protein expression of the genes. The two methods that were applied take advantage of the fact that the eigendecomposition of the $N x N$ graph Laplacian matrix $\boldsymbol{L} = \boldsymbol{U\Lambda U}^T$ forms the equivalent of a Fourier basis on a graph, where $\boldsymbol{U}$ are the $N$ Fourier basis vectors and the $N$ eigenvalues $\boldsymbol{\Lambda}$ represent the corresponding frequencies.
 \par
Graph sampling (GS) aims to find nodes where signal energy is the most concentrated for frequencies in the range $(f_{min}, f_{max})$. The \textit{local graph coherence} at node $i$ of order $k$ is defined as the square of the $i$-th entry of the $k$-th eigenvector $u_{ik}$ of the Laplacian, which is a measure for how localized the first $k$ Fourier modes are on node $i$ \cite{Puy2018}. By choosing the first $K$ indices $i$ that maximize $\Sigma_{k=f_{min}}^{f_{max}} u_{ik}^2$, the data can be reduced to the $K$ genes whose read-count information has the most value based on their location in the network for the chosen frequency range. In particular, we applied the GS algorithm for only low frequencies (below N/2) and only high frequencies (above N/2). 
\par
The idea behind graph-based filtering (GBF) is essentially to transform the data into the spectral domain and retain components above or below a certain frequency. The Graph Fourier Transform is given by
\begin{equation}
\boldsymbol{\hat{x}} = \boldsymbol{U}^T \boldsymbol{x}.
\end{equation}
\par
In our GBF algorithm, the graph signal is projected only onto the $K$ eigenvectors associated to eigenvalues below or above a cut-off frequency, resulting in a $K$-dimensional signal. For example, choosing the $K$ lowest frequencies,
\begin{equation}
\boldsymbol{\hat{x}_{GBF}} = \boldsymbol{U}[0:K]^T \boldsymbol{x}.
\end{equation} 
\par
We used the the $K$ lowest and highest frequencies to transform the original data. GBF potentially mitigates issues due to batch effects that might appear as a low-frequency component in the graph signal. Similarly, the presence of drop-outs might manifest itself as a high-frequency component and thus be filtered when considering only low-frequency eigenvectors.

\subsection{Machine Learning Methods}
Within this project, we applied four different types of classifiers: Logistic regression, random forest, neural net and xg boost.
\par

The neural net consists of six fully connected layers used as classifier into the two classes not stem cell and stem cell. The probabilities are then computed using a softmax classifier. The net was trained with stochastic gradient descent on the cross entropy loss in ten epochs. In order to find the best learning rate and regularization constant, validation on part of the training set was conducted for different parameters during one epoch each. The best learning rate and weight decay were retained after two refinements. During the training of the neural net, a learning weight decay was used to avoid oscillating across the optimum.


\section*{Results}

\section*{Conclusion}

%%% Bibliography
\bibliographystyle{IEEEtran}
\bibliography{literature-project2}


\end{document}
