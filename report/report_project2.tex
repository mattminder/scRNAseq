\documentclass[10pt,conference,compsocconf]{IEEEtran}

\usepackage{hyperref}
\usepackage{graphicx}	% For figure environment
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{float}
\usepackage{url}
\newcommand{\beginsupplement}{%
	\setcounter{table}{0}
	\renewcommand{\thetable}{S\arabic{table}}%
	\setcounter{figure}{0}
	\renewcommand{\thefigure}{S\arabic{figure}}%
}

\begin{document}
\title{CS-433 Machine Learning Project 2}

\author{
	Matthias Minder, Zora Oswald, Silvan Stettler\\
}

\maketitle

\begin{abstract}
	Abstract...
\end{abstract}

\section*{Introduction} 
The recently developed method of single cell RNA sequencing (scRNA-seq) allows to measure the amount of RNA from a specific gene at the single cell resolution. This gives valuable insight into the properties and cellular function of single cells in a whole population of cells. High throughput methods allow to analyze thousands of cells simultaneously. scRNA-seq results in so-called read-count matrices (RCMs) which indicate the expression level of a given gene in a given cell.
\par 
The emergence of scRNA-seq has led to the discovery of many new cell populations based on their gene expression profile. The question thus naturally arises whether it would be possible to predict cell types using a machine learning approach. To this effect, classifiers can be trained on various publicly available data sets to infer cell types on a new data set \cite{Schwalie2017}. Of special interest is the detection and \textit{de novo} discovery of stem cells in tissues for which no stem cell population has been characterized. It is still unknown whether there exist specific biomarkers for multipotent stem cells allowing to identify them across tissues, which makes this problem attractive to solve. 
\par
However, several challenges are associated with working with scRNA-seq data. The three most predominant issues are the following: Differences in protocols and procedures give rise to batch effects, leading to substantial overall differences between datasets of different sources. Secondly, cell-type annotation is based on clusters of the dataset itself and thus depends on the  analysis and interpretation of the data. This may lead to biases when basing analysis on the annotated clusters. Thirdly, the obtained data is perturbed by so called drop-out events, where the read-counts for a given gene is measured to be zero, even if there were a signal. The result is that RCMs are very sparse. 
\par
Additional issues arise from a machine learning perspective: Since the expression of different genes can be functionally related or controlled by the same transcriptional regulatory program, some features are highly correlated. The scRNA-seq data can thus be thought of as being on a sub-dimensional manifold. However, due to the noisy nature of the data, identifying highly correlated features is difficult. An accurate representation of this manifold is key for obtaining stable results that generalize well to other data sets in order to overcome batch-effects. Moreover, a good such representation also reduces the impact of drop-outs: If several genes are simultaneously expressed for a given biological process, and a subset of these aren't detected due to drop-outs, the other genes could correct this. Naturally, such an approach doesn't work when the drop-out rate is too high. Overall, this nature of scRNA-data suggests that the application of dimensionality reduction prior to method training will yield results that perform better on new, unrelated datasets.
\par
Within this report, we train different stem cell classifiers on multiple published scRNA-seq datasets. The predictive performance is assessed using data from different sources in order to finally determine the best-performing classifier. The presented classifiers are based on different, well-established machine learning methods and were trained on data subjected to different data transformations and dimensionality reduction techniques.

\section*{Methods}
\subsection{Experimental Setup}
For the entire analysis, 17 publicly available scRNA-seq datasets from mature \textit{mus musculus} were used \cite{Campbell2017, Chen2017, Dahlin2018,Dulken2017, Gokce2016, Kowalczyk2015, Haber2017, Hochgerner2018, Rodda2018, Schwalie2018, Nestorowa2016, Park2018, Shah2018, TabulaMuris2017, Tasic2016, Zeisel2018}. These data sets were split into three sets, set A (eleven data sets), set B (three data sets) and set C (four data sets). Two types of classifiers were trained, which will be called basic and nested classifiers. The basic classifiers were trained on set A, and their predictive performance was assessed in terms of the area under the receiver operating characteristic curve (AUC) on the set B and C. The nested classifiers were trained as follows: Using the basic classifiers, predictions were generated for the data in set B. Then, the resulting predictions by all basic classifiers were used as training set for a second classifier, whose performance was assessed and compared with the basic classifiers on set C. By constructing the two-layer nested classifiers, we hoped to be able to obtain a final model which is less prone to batch effects. 
Different basic classifiers were trained on a total of eight data transformations described below, six of which are network-based. 
\begin{table}[H]
	\centering
	\begin{tabular}{|r|c|c|c|}
		\hline
		\textbf{Classifier type} & \textbf{Set A} & \textbf{Set B} & \textbf{Set C} \\ \hline
		Basic & Training & Testing & Testing \\
		Nested & - & Training & Testing \\
		\hline
	\end{tabular}
	\caption{Use of datasets}
\end{table}

\subsection{Dataset Preparation}
Cell type annotation was taken from the clustering done in the original papers. All three sets consist only of cell types which were determined as being clearly stem or non-stem in order to avoid introducing a bias into the model. Notably, progenitors, endothelial and fibroblast cells were excluded from the analysis. For the set A, the cells were down-sampled to be of equal proportions from the three different germ layers, and within each germ layer to be 50\% stem and 50\% non-stem. This was chosen in order to avoid introducing a tissue-specific bias in determining stem-ness. 
\par
Since different datasets measure the expression of different genes, one has to choose which genes to use for the analysis in order to be able to join different datasets. The genes retained for our analysis were selected as follows: For all eleven sets within our train set, we determined whether they contained stem cells, non-stem cells or both. Then, the genes common to all sets with stem-cells were combined with the genes present in all sets containing non-stem cells. In this way, genes that are only expressed in either stem or non-stem cells are retained while minimizing the number of genes with missing values. This resulted in 13'587 genes retained for further analysis.
\par
For datasets in which a necessary gene isn't represented, we set the gene expression to zero. This is based on the heuristic that such genes are lowly expressed in these datasets, as otherwise they would have been sufficiently measured to be retained in the final dataset. 
\par
After retaining only the necessary genes and filling missing values with zero, we normalized the expression values to transcripts per million before transforming the values with $ln(1+x)$. This is standard procedure for scRNA-seq data. All subsequent transformations and training steps were based on data in this format. 

\subsection{Gene Network Construction}
Taking into account external information about the underlying structure is a way to reduce the influence of set specific batch effects. To this effect, we included a protein interaction network, which we then use as topology to process the expression signal. Protein interaction networks are representations of the physical and biochemical interaction between proteins in an organism. The protein interaction network was converted to a gene network by replacing proteins with the genes that encode them. 
\par
The protein interaction data that was used is available in the STRING database (\url{www.string-db.org}) \cite{Szklarczyk2016}. The weight of the edges between individual proteins, which form the nodes, are a measure of how confidently an interaction can be judged to be true. Mapping of genes to their proteins was done using the Ensembl database for \textit{mus musculus} (\url{www.ensembl.org}) \cite{Zerbino2017}. 
For the creation of our network, only the proteins that could be associated to an expressing gene were kept.
Self-loops that resulted from genes whose expression produces multiple proteins and isolated nodes (no link to another node) were removed, yielding a network with 20'330 genes forming nodes that are connected by 11'856'336 edges. It has to be mentioned that the gene network is constructed based on the entire dataset that was available from the sources mentioned above. Contrary to the analysed data, the scope of the network does not limit itself to the genes found in a particular type of cells, such as tissue.  \\

\begin{figure}
	\centering
	\includegraphics[width=0.45\textwidth]{network.png}
	\caption{Schematic of network creation.  The genes \textit{A, B, C, D} replace the proteins which they express. Proteins that cannot be associated to a gene or vice versa are removed. Resulting self-loops, asi in the case of replacing protein c and d with gene \textit{C} are also removed. Moreover, between gene \textit{A} and \textit{C} two edges of weight 1 and 2 respectively would be created. These edges are summarized in one edge of weight 3. }
	\label{fig:network_creation}
\end{figure}
The process of creating the gene network is schematically shown in Figure \ref{fig:network_creation}. In the case that the replacing of the proteins produces multiple edges between genes, a single edge with a weight equal to the sum of all the individual edge weights is created instead.
\par
The original score $s_{ij}$ of a link between nodes $i$ and $j$ was used to compute an equivalent distance, where high scores result in a short distance. Subsequently, new link weights $W_{ij}$ were set using a Gaussian kernel.

\begin{equation}
W_{ij} = \exp \{- \frac{1}{2}\frac{1}{(s_{ij} \sigma)^2}\}
\end{equation}

\subsection{Feature Creation through Graph Signal Processing}
The scRNA-sec data can be transformed into a graph signal by assigning the count of expressed genes to the corresponding gene in the network, yielding a signal $\boldsymbol{x} \in \mathbb{R}^N$, where $N$ is the total number of nodes. Genes whose expression was not present as a feature in the scRNA-sec data are assigned zero. 
\par
After mapping the data onto the resulting graph, graph signal processing (GSP) can be leveraged to find a lower-dimensional manifold that embeds the original data, based purely on the constructed network. The two methods that were applied take advantage of the fact that the eigendecomposition of the $N \times N$ graph Laplacian matrix $\boldsymbol{L}$ forms the equivalent of a Fourier basis on a graph. Given the eigendecomposition $\boldsymbol{L} = \boldsymbol{U\Lambda U}^T$, $\boldsymbol{U} = [ \boldsymbol{u}_1 ... \boldsymbol{u}_N]$ are the $N$ Fourier basis vectors and the $N$ eigenvalues $\boldsymbol{\Lambda}$ represent the corresponding frequencies \cite{Puy2018}.
\par
Graph sampling (GS) is a way to identify genes which are of particular importance to the network. In particular, it identifies nodes where signal energy is the most concentrated for frequencies in the range $(f_{min}, f_{max})$ \cite{Menoret2017}. The \textit{local graph coherence} at node $i$ of order $k$ is defined as the square of the $i$-th entry of the $k$-th eigenvector $u_{ik}$ of the Laplacian, which is a measure for how localized the first $k$ Fourier modes are on node $i$ \cite{Puy2018}. By choosing the first $K$ indices $i$ that maximize $\Sigma_{k=f_{min}}^{f_{max}} u_{ik}^2$, the data can be reduced to the $K$ genes whose read-count information has the most value based on their location in the network for the chosen frequency range. In particular, we applied the GS algorithm for only low frequencies (below $\frac{N}{2}$) and only high frequencies (above $\frac{N}{2}$). 
\par
The idea behind graph frequency sampling (GFS) is essentially to transform the data into the spectral domain and retain components above or below a certain frequency \cite{Rui2016}. The Graph Fourier Transform (GFT) $\boldsymbol{\hat{x}}$ of a signal $\boldsymbol{x}$ and its inverse are given by
\begin{align}\label{equ:GFT}
\boldsymbol{\hat{x}} &= \boldsymbol{U}^T \boldsymbol{x}\\ \label{equ:iGFT}
\boldsymbol{x} &= \boldsymbol{U} \boldsymbol{\hat{x}}
\end{align} 
In the GFS algorithm, the graph signal is projected only onto the $K$ eigenvectors associated to eigenvalues below or above a cut-off frequency, resulting in a $K$-dimensional signal $\boldsymbol{\hat{x}_{GFS}}$. For example, choosing the $K$ lowest frequencies,
\begin{equation}
\boldsymbol{\hat{x}_{GFS}} = [ \boldsymbol{u}_1 ... \boldsymbol{u}_K]^T \boldsymbol{x}.
\end{equation} 
\par
We used both the $K$ lowest and highest frequencies separately to transform the original data. GFS using high frequencies (HF) potentially mitigates issues due to batch effects that might appear as a low-frequency component in the graph signal. Similarly, the presence of drop-outs might manifest itself as a high-frequency component and thus be filtered when considering only low-frequency (LF) eigenvectors.
\par
The GFT was also used to implement graph filtering with a simple low or pass rectangle filter in the graph spectral domain. After transforming the data into a graph signal as described previously, the GFT is computed (Equation \ref{equ:GFT}). The components of the resulting spectrum that are above or below a cut-off frequency are set to zero. Subsequently, the inverse GFT (Equation \ref{equ:iGFT}) is applied to obtain a filtered version of the original signal. While this process does not reduce the dimensionality of the data, it could provide insight on validity of the network creation process and reduce noise.

\subsection{Data Transformations}
In total, 9 different data transformation methods were used and compared to a baseline model. The baseline model for each of the four classifiers is obtained by removing features with variance smaller than 0.1 from the raw data and then training the classifier in question on the remaining features. The data transformation methods that were tested are PCA, Graph sampling (LF and HF), Graph frequency sampling (LF and HF), Graph filtering (LF and HF), Graph filtering (LF and HF) followed by PCA, and a nested method that combines all the above. Graph filtering (LF and HF) do not reduce the dimensionality of the data. For PCA, the number of components was chosen to be $K = 500$ based on the explained variance proportion, which is around 50\% for 500 components (see Figure \ref{fig:explvar}). For the other dimensionality reduction methods that are based on the network, also 500 components were chosen for consistency.

\subsection{Machine Learning Methods}
Within this project, we applied four different types of classifiers to all our data transformations: L1-regularized logistic regression, random forest, neural networks and XGboost.
\par
Logistic regression classifiers were trained using the scikit-learn package in python \cite{scikit-learn}. The regularization parameter was chosen to be the best in accuracy using the built in ten-fold cross-validation functionality using a grid-size of 40. The solution was found using stochastic average descent, with a tolerance of 0.005. 
\par
The random forest classifier was also trained using scikit-learn. For training, 5000 fully grown, unpruned trees were constructed. At every split, $\sqrt{n_{features}}$ were considered when looking for the best split.
\par
Training of XGBoost was done using the python package xgboost \cite{Chen:2016:XST:2939672.2939785}. In order to prevent overfitting, the best classifier was selected based on the best  accuracy on a validation set consisting of 20\% of the training data. A learning rate of 0.2 and a maximum tree depth of three. For all other parameters, default values were used.  
\par
The neural network consists of fully connected layers alternating with ReLU activation functions using PyTorch \cite{paszke2017automatic}. It classifies into two classes (non-stem or stem cell) and returns the probabilities using a softmax classifier. Six layers were used for the dimensionality reduced data. Due to a lack of working memory, a hidden layer fc0 with 500 nodes was added at the front of the network for the data with full dimensionality. This allows us to compare the addition of a layer with 500 nodes to a PCA of the same number of dimensions. The architecture is shown in Table \ref{tab:ArchitectureNN} below.

\begin{table}[H]
	\centering
	\begin{tabular}{rccccccc}
\hline
  \textbf{Layer} &  fc0 &  fc1 & fc2 & fc3 & fc4 & fc5 & fc6 \\
  \textbf{Nb Nodes} &  500 &  2500 & 1000 & 200 & 100 & 20 & 2 \\
\hline
\end{tabular}
	\caption{Architecture of the neural network. fc0 is only present for data whose dimensions are not reduced.}
	\label{tab:ArchitectureNN}
	\vspace{-8mm}
\end{table}

The network was trained with stochastic gradient descent on the cross entropy loss in 40 epochs. The best learning rate and regularization constant were found by validating on 15\% of the train set. During the training of the neural network, a learning weight decay was used to avoid oscillating across the optimum.
\par
For the nested models, the same four classifiers were used. But instead of using the data directly, the predictions of all data transformations and methods were used as input.

\section*{Results}
The performance of each classifier was assessed using AUC.
The AUC of the basic classifiers on set B are summarized in Figure \ref{fig:train_acc} below.
\begin{figure}[H]
	\centering
	\includegraphics[width=0.45\textwidth]{train_auc.png}
	\caption{AUC scores on set B for the basic classifiers.}
	\label{fig:train_acc}
\end{figure}
We observe that the impact of the choice of data transformation is significant.
The best results were achieved using the network-based GS LF transformation with a maximum AUC of 0.963 for the random forest classifier. Moreover, HF filtering and GS LF with XGBoost perform well, with an AUC of 0.951 and 0.929. All other models perform worse than the baseline model trained with XGBoost and random forest with an AUC of 0.910 and 0.900 respectively. Notably, the neural network on HF followed by PCA performs quite good, with an AUC of 0.878 performing only slightly worse than the baseline model.
\par  
The following AUC scores were obtained on set C with all classifiers, including the nested classifier that was previously trained on the predictions of the basic classifiers on set B (Figure \ref{fig:train_acc}).

\begin{figure}[H]
	\centering
	\includegraphics[width=0.45\textwidth]{test_auc.png}
	\caption{AUC scores on set C for all classifiers }
	\label{fig:test_acc}
\end{figure}
It becomes immediately apparent that the nested classifiers did not perform better than their non-nested counterparts. The attempted improvement and resistance to batch effects was thus not achieved, likely due to overfitting on Set B on which it was trained in the second layer. Moreover, what is of note here is that the best-performing method on set C, GS LF with random forest, performs very poorly with an AUC of 0.574, and is only barely better than just deciding by chance. Similarly, GS LF with XGBoost doesn't perform well either, with an AUC of 0.79. However, the neural network on HF followed by PCA has the best AUC score (0.941), followed by logistic lasso (0.940) on data with same transformation. This is followed by XGBoost, logistic lasso and neural networks trained on PCA transformed data (AUC of 0.934, 0.925, and 0.924).  

While GS LF produced the best results on set B, PCA clearly yield the best AUC scores on set C, outperforming the baseline model with all classifiers. The performance with the network-based dimensionality reduction methods compared to the baseline model is heavily dependent on the choice of classifier. 
Based on the results of set B and C, PCA seems to be the most versatile dimensionality reduction method, producing results that are similar or superior to the baseline model. The scores obtained with the graph-filtered data without dimensionality reduction on set C are similar or higher than the baseline model, but no clear winner between LF and HF can be determined. 
\par
In order to understand how our final classifier performed on cells that are transitioning between stem- and non-stem cells, we generated prediction on the Joost dataset containing cells of the hair follicle. Figure REFERENCE shows the predicted probabilities for individual cells grouped by cell type. Cell types are ordered to follow the lineage ordering as determined in the Joost paper. 

\section*{Conclusion}
As a follow-up to this report, it would be interesting to reconstruct the decision making process of the best-performing classifiers in order to backtrack the importance of individual genes in stemness decision. This may give valuable biological insights. Moreover, it could be of interest to take into account other networks in order to analyze whether they improve the classifier performance. A network that also yields consistently good predictions could be of interest for other applications, such as batch effect and drop-out correction\cite{vanDijk2017}. Additionally, the application of existing batch-effect and drop-out correction techniques previous to classifier training may improve performance. Finally, since scRNA-seq gets increasingly popular, retraining the classifier when more data is available is of interest. 
\par
%All in all, we've created a valuable tool for the detection of stem cells. We've shown that the classifier performs reasonably well on independent test data. 



%%% Bibliography
\bibliographystyle{IEEEtran}
\bibliography{literature-project2}

\beginsupplement
\onecolumn
\begin{table}[H]
	\centering
	\begin{tabular}{r|rrrrrrrrrr}
	\hline
	& Base feat. & Filter HF & Filter LF & Filter HP + PCA & Filter LP + PCA & GFS HF & GFS LF&GS HF &GS LF & PCA  \\ \hline
	 log lasso & 86.5 & 80.5 & 83.6 & 82.9 & 84.6 & 73.8 & 63.5 & 80.4 & 80.5 & 83.7 \\
	 randomForest & 90.1 & 87.6 & 87.1 & 77.6 & 78.4 & 83.5 & 85.6 & 87.3 & 96.3 & 68.0 \\
	 xgboost & 91.0 & 95.1 & 83.5 & 68.7 & 82.6 & 82.1 & 76.8 & 77.4 & 92.9 & 78.2 \\
	 neural network & 78.6 & 80.0 & 80.0 & 87.8 & 83.9 & 78.4 & 50.0 & 78.8 & 85.8 & 87.6 \\
	\hline
	\end{tabular}
	\caption{AUC on set B, raw data in \%}
\end{table}

\begin{table}[H]
	\centering
	\begin{tabular}{r|rrrrrrrrrrr}
	\hline
	& Base feat. & Filter HF & Filter LF & Filter HP + PCA & Filter LP + PCA & GFS HF & GFS LF&GS HF &GS LF & PCA & nested \\ \hline
	 log lasso & 68.7 & 91.0 & 83.8 & 94.0 & 91.2 & 73.1 & 63.4 & 84.0 & 79.5 & 92.5 & 71.3 \\
	 randomForest & 70.9 & 76.3 & 80.7 & 71.7 & 64.4 & 80.2 & 59.2 & 75.9 & 58.0 & 79.8 & 88.1 \\
	 xgboost & 83.8 & 84.4 & 82.8 & 75.6 & 79.2 & 82.1 & 70.8 & 82.5 & 79.7 & 93.4 & 88.4 \\
	 neural network & 84.1 & 89.4 & 88.2 & 94.1 & 90.8 & 59.6 & 50.0 & 69.2 & 78.2 & 92.4 & 75.8 \\
	\hline
	\end{tabular}
	\caption{AUC on set C, raw data in \%}
\end{table}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\textwidth]{pca_explvar.png}
	\caption{Explained variance as a function of the number of components chosen for PCA}
	\label{fig:explvar}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.45\textwidth]{joost.pdf}
	\caption{Predicted stemness probabilities as determined by best-performing classifier on subset of cell-types in Joost 2016 \cite{Joost2016} data set. Arrows on the left side show the transition of stemness across cell-types, as determined in the original paper.}
	\label{fig:joost}
\end{figure}

	
\end{document}
